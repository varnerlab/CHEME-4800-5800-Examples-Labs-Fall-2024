{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbbfc7c9-f794-4e1c-9bf3-e121bcaf6fd8",
   "metadata": {},
   "source": [
    "## Example: Properties of a Three-State Hidden Markov Models\n",
    "This example will familiarize students with building and using [Hidden Markov Models](https://en.wikipedia.org/wiki/Hidden_Markov_model) to model random phenomena. In this example, we'll use the previous three-state model and assume the hidden states are mapped to the mood set: \n",
    "\n",
    "$$\n",
    "\\mathcal{S}\\equiv\\left\\{\\text{happy},\\text{neutral},\\text{sad}\\right\\}\n",
    "$$\n",
    "\n",
    "We'll then map the hidden states $s_{i}\\in\\mathcal{S}$ to outward manifestations of mood which are observable, as represented by [Emoji](https://en.wikipedia.org/wiki/Emoji)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdaa6c4-797c-496c-82a0-7b3702acc022",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Let's load some packages that are required for the example by calling the `include(...)` function on our initialization file `Include.jl`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e1ed4f5-4cf6-4963-8720-07745a640d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "include(\"Include.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52ba3d8-992f-4eea-8c3f-f920562ebbef",
   "metadata": {},
   "source": [
    "## Prerequisites \n",
    "Before we start this example, let's set up the `iterate(...)` method and specify some constants. We'll use the `iterate(...)` method to compute the stationary distribution $\\pi$.\n",
    "```julia\n",
    "iterate(P::Array{Float64,2}, counter::Int; \n",
    "        maxcount::Int = 100, œµ::Float64 = 0.1) -> Array{Float64,2}\n",
    "```\n",
    "> Iteratively computes a stationary distribution. Computation stops if ||P_new - P|| < œµ or the max number of iterations is hit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d6931b9-4f24-45a2-b83a-217b87768c64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function iterate(P::Array{Float64,2}; \n",
    "        maxcount::Int = 100, œµ::Float64 = 0.1)::Array{Float64,2}\n",
    "\n",
    "    # initialize -\n",
    "    counter = 1; # initialize the iteration counter\n",
    "    is_ok_to_stop = false; # flag for while loop\n",
    "    P_new = nothing; # initialize P_new matrix\n",
    "    \n",
    "    # main loop - iterate until the difference ||P_new - P|| <= œµ -or- we run out of iterations\n",
    "    while (is_ok_to_stop == false)\n",
    "        P_new = P^(counter+1); # compute new P matrix by raising to counter + 1 power\n",
    "        if (norm(P_new - P) <= œµ || counter >= maxcount)\n",
    "            is_ok_to_stop = true;\n",
    "        end\n",
    "        counter += 1; # update the counter\n",
    "    end\n",
    "\n",
    "    # return -\n",
    "    return P_new;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71d96d3-6d48-4eb8-a701-fb1f8db1b3fa",
   "metadata": {},
   "source": [
    "#### Constants \n",
    "In the simulations below, we'll need some constant values that we set here. In particular, we set a value for the `number_of_hidden_states` variable, the `number_of_simulation_steps` variable (the number of steps that we take in a Markov Chain), and the `number_of_observable_states` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb7f7768-3f5c-48aa-9509-1a1be7664267",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "number_of_hidden_states = 3; # how many hidden states do we have?\n",
    "number_of_observable_states = 3; # how many observable states do we have?\n",
    "number_of_simulation_steps = 50000; # number of simulation steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744e52b9-f72b-4f78-851b-8c502b14582a",
   "metadata": {},
   "source": [
    "## Task 1: Setup the Transition matrix $\\mathbf{P}$\n",
    "In this task, we'll set up the transition matrix $\\mathbf{P}$ for a three-state [Markov chain model](https://en.wikipedia.org/wiki/Markov_chain):\n",
    "<div>\n",
    "    <center>\n",
    "        <img src=\"figs/Fig-ThreeState-HMM-Schematic.svg\" width=\"580\"/>\n",
    "    </center>\n",
    "</div>\n",
    "In this example we have three states $\\mathcal{S}\\equiv\\left\\{\\text{happy},\\text{neutral},\\text{sad}\\right\\}\n",
    "$ and the probability of moving between state $i\\rightarrow{j}$, denoted as $p_{ij}$, is an element of the matrix $\\mathbf{P} \\in \\mathbb{R}^{3\\times{3}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "027bce64-113c-4ad8-ae0a-a1d3ffa7f1b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "P = [\n",
    "    0.05 0.95 0.0 ; # moves for state 1 = happy\n",
    "    0.6 0.2 0.2 ; # moves for state 2 = neutral\n",
    "    0.0 0.3 0.7 ; # moves for state 3 = sad\n",
    "];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d154977b-f3ed-4739-8395-54aa36410b15",
   "metadata": {},
   "source": [
    "### Check: do the rows of the transition matrix $\\mathbf{P}$ sum to `1`?\n",
    "We know that the rows of the transition matrix $\\mathbf{P}$ must sum to `1`, i.e., if we are in state $s_{i}\\in\\mathcal{S}$ at time $t$, then at time $t+1$ we have to be in $s_{j}\\in\\mathcal{S}$. \n",
    "* Let's check if the transition matrix $\\mathbf{P}$ meets this criteria using the [@assert macro](https://docs.julialang.org/en/v1/base/base/#Base.@assert) by iterating over the rows of the transition matrix $\\mathbf{P}$ and checking the sum of each row. If any row does not meet this criterion, an [AssertionError](https://docs.julialang.org/en/v1/base/base/#Core.AssertionError) will be thrown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5df203b0-243e-45d1-b75d-f87396debdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i ‚àà 1:number_of_hidden_states\n",
    "    @assert sum(P[i,:]) == 1\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28848c32-d153-4953-8245-b935df1a8c23",
   "metadata": {},
   "source": [
    "Now that we are sure that the transition matrix $\\mathbf{P}$ is proper, we populate the `hidden_state_probability_dictionary`, which holds the [categorical distribution](https://en.wikipedia.org/wiki/Categorical_distribution) modeling the transition probability for each hidden state $s\\in\\mathcal{S}$, i.e., the probability that we transition from state $i\\rightarrow{j}$ in the next time step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04e8b0ca-95c0-4a48-8983-92b1e462e198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64, Categorical{P} where P<:Real} with 3 entries:\n",
       "  2 => Categorical{Float64, Vector{Float64}}(support=Base.OneTo(3), p=[0.6, 0.2‚Ä¶\n",
       "  3 => Categorical{Float64, Vector{Float64}}(support=Base.OneTo(3), p=[0.0, 0.3‚Ä¶\n",
       "  1 => Categorical{Float64, Vector{Float64}}(support=Base.OneTo(3), p=[0.05, 0.‚Ä¶"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_state_probability_dictionary = Dict{Int,Categorical}();\n",
    "for i ‚àà 1:number_of_hidden_states\n",
    "    hidden_state_probability_dictionary[i] = Categorical(P[i,:])\n",
    "end\n",
    "hidden_state_probability_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803924e3-d7c7-4140-a7a2-6283cf61c432",
   "metadata": {},
   "source": [
    "## Task 2: Compute the stationary distribution $\\pi$\n",
    "In this task, we'll compute the stationary distribution $\\pi$ for our example [Markov chain](https://en.wikipedia.org/wiki/Markov_chain) using the `iterate(...)` method defined above. This version of the method uses a `while-loop`; we iterate until the difference $||\\mathbf{P}^{i+1} - \\mathbf{P}^{i}|| < \\epsilon$, or we run out of iterations (the iteration counter exceeds the `maxcount` argument)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aba93bab-b86e-441a-9c62-62e0a3bf53b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching iterate(::Matrix{Float64}; œµ::Float64, maxcount::Int64)\nYou may have intended to import Base.iterate\nThe function `iterate` exists, but no method is defined for this combination of argument types.\n\n\u001b[0mClosest candidates are:\n\u001b[0m  iterate(::Matrix{Float64}, \u001b[91m::Int64\u001b[39m; maxcount, œµ)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[35mMain\u001b[39m \u001b[90m\u001b[4mIn[5]:1\u001b[24m\u001b[39m\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching iterate(::Matrix{Float64}; œµ::Float64, maxcount::Int64)\nYou may have intended to import Base.iterate\nThe function `iterate` exists, but no method is defined for this combination of argument types.\n\n\u001b[0mClosest candidates are:\n\u001b[0m  iterate(::Matrix{Float64}, \u001b[91m::Int64\u001b[39m; maxcount, œµ)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[35mMain\u001b[39m \u001b[90m\u001b[4mIn[5]:1\u001b[24m\u001b[39m\n",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[15]:1"
     ]
    }
   ],
   "source": [
    "œÄÃÑ = iterate(P, œµ = 1e-9, maxcount = 10000) # iterative version of iterate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d746adb4-3b7f-45b6-ba0d-62dc94d98ac2",
   "metadata": {},
   "source": [
    "Finally, create a [categorical distribution](https://en.wikipedia.org/wiki/Categorical_distribution) using the stationary probability of our Markov chain using the [Distributions.jl](https://github.com/JuliaStats/Distributions.jl) package, save this distribution in the variable `d`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90b6b697-634c-4de9-be5b-e3ff5e621281",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `œÄÃÑ` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `œÄÃÑ` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[17]:1"
     ]
    }
   ],
   "source": [
    "d = Categorical(œÄÃÑ[1,:]); # steady-state stationary distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baa3f4c-8ad4-438e-a33f-952d9eb004e8",
   "metadata": {},
   "source": [
    "## Task 3: Setup the Emission Probability Matrix $\\mathbf{E}$\n",
    "In this task, we setup the Emission Probability Matrix $\\mathbf{E}$, which links the hidden and observable [Markov chain](https://en.wikipedia.org/wiki/Markov_chain) states.\n",
    "Now that we have the stationary distribution for the hidden layer of our [Hidden Markov Model](https://en.wikipedia.org/wiki/Hidden_Markov_model) let's set up the emission probability matrix $\\mathbf{E}$ and save it in the `EPM` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a9a2443-3fee-49e3-b8e1-d081c0d2cfbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "E = [\n",
    "    0.90 0.05 0.05 ; # 1 happy (but sometimes we see other faces)\n",
    "    0.05 0.90 0.05 ; # 2 neutral (but sometimes we see other faces)\n",
    "    0.05 0.05 0.90 ; # 3 sad (but sometimes we see other faces)\n",
    "];\n",
    "# E = diagm(ones(3)) # we never have a missed guess ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c062d7a4-9ecb-4cb6-ad3c-00d8269e9c08",
   "metadata": {},
   "source": [
    "Populate the `emission_probability_dict`, which holds the [categorical distribution](https://en.wikipedia.org/wiki/Categorical_distribution) modeling the emission probability for each hidden state $s\\in\\mathcal{S}$, i.e., the probability of what output $o_{i}\\in\\mathcal{O}$ we expect to see if we are in $s\\in\\mathcal{S}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2624ec44-a5df-4a0e-9c65-c04268444736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emission_probability_dict = Dict{Int,Categorical}()\n",
    "for i ‚àà 1:number_of_hidden_states\n",
    "    emission_probability_dict[i] = Categorical(E[i,:])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9bb6ca9-c1fe-48a5-a8a2-ed912fb450e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64, Categorical{P} where P<:Real} with 3 entries:\n",
       "  2 => Categorical{Float64, Vector{Float64}}(support=Base.OneTo(3), p=[0.05, 0.‚Ä¶\n",
       "  3 => Categorical{Float64, Vector{Float64}}(support=Base.OneTo(3), p=[0.05, 0.‚Ä¶\n",
       "  1 => Categorical{Float64, Vector{Float64}}(support=Base.OneTo(3), p=[0.9, 0.0‚Ä¶"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emission_probability_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077be025-c9c5-44ca-83cf-e7d90868267e",
   "metadata": {},
   "source": [
    "### 3. Simulate the output from the HMM\n",
    "In this task, we simulate the evolution of the hidden Markov model.\n",
    "Let's implement the pseudo-code from the lecture, where each observable state corresponds to an [Emoji](https://en.wikipedia.org/wiki/Emoji). We store this relationship in the `observable_emoji_map` variable, which is a dictionary with keys corresponding to observable states $o\\in\\mathcal{O}$ and [Emoji](https://en.wikipedia.org/wiki/Emoji) values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4250dbab-0c3e-4de2-a875-a0daa7340518",
   "metadata": {},
   "outputs": [],
   "source": [
    "observable_emoji_map = Dict{Int,Any}();\n",
    "observable_emoji_map[1] = `üòÑ`;\n",
    "observable_emoji_map[2] = `üòê`;\n",
    "observable_emoji_map[3] = `üòû`;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b42fdb-943c-4caf-9235-3e3d3c3f4085",
   "metadata": {},
   "source": [
    "__Simulation algorithm__: For `number_of_simulation_steps`, starting from some initial state $s\\in\\mathcal{S}$: \n",
    "* First we get the hidden state distribution from the `hidden_state_probability_dictionary`, we then generate a new state $s^{\\prime}$, access the emission distribution from the `emission_probability_dict` that corresponds to $s^{\\prime}$, and we generate a random observable output $o_{i}$.\n",
    "* Next, we save both the hidden state $s^{\\prime}$ and the output $o_{i}$ for this iteration in the `hidden_simulation_dict` and `output_simulation_dict` variables, respectively.\n",
    "* Finally, we update the current state $s_{i}\\leftarrow{s}^{\\prime}$ and move onto the next iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "417b5fcc-fd6c-4a81-b6d3-b68d6d412ae2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_simulation_dict = Dict{Int,Any}()\n",
    "hidden_simulation_dict = Dict{Int,Int}();\n",
    "s·µ¢ = 1;\n",
    "for i ‚àà 1:number_of_simulation_steps\n",
    "\n",
    "    # get the categorical distribution for s·µ¢ \n",
    "    d·µ¢ = hidden_state_probability_dictionary[s·µ¢];\n",
    "    \n",
    "    # compute the *next* hidden state -\n",
    "    s‚Ä≤ = rand(d·µ¢);\n",
    "\n",
    "    # next, compute what output we see from this state -\n",
    "    o·µ¢ = emission_probability_dict[s‚Ä≤] |> o -> rand(o);\n",
    "\n",
    "    # capture -\n",
    "    hidden_simulation_dict[i] = s‚Ä≤\n",
    "    output_simulation_dict[i] = observable_emoji_map[o·µ¢]\n",
    "\n",
    "    # update -\n",
    "    s·µ¢ = s‚Ä≤;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebce90f3-1a46-40bd-bee1-edebc19a23b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,`üòÑ`\n",
      "3,`üòû`\n",
      "2,`üòê`\n",
      "3,`üòû`\n",
      "3,`üòû`\n",
      "3,`üòÑ`\n",
      "3,`üòû`\n",
      "3,`üòû`\n",
      "3,`üòû`\n",
      "3,`üòû`\n",
      "3,`üòû`\n",
      "3,`üòû`\n",
      "3,`üòû`\n",
      "2,`üòû`\n",
      "2,`üòû`\n",
      "1,`üòÑ`\n",
      "2,`üòê`\n",
      "3,`üòû`\n",
      "2,`üòê`\n",
      "3,`üòû`\n"
     ]
    }
   ],
   "source": [
    "foreach(i->println(\"$(hidden_simulation_dict[i]),$(output_simulation_dict[i])\"), 1:20); # wow, that's nice ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6462e590-6d9e-4a37-a288-3ece5dc097ef",
   "metadata": {},
   "source": [
    "Let's do a quick test: what is the probability that we observe a particular value? We'll compute this by iterating over the simulation output and counting the times a `test_value` is encountered. We'll then estimate the probability as the number of positive samples divided by the total number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe9a418b-0912-42b4-a471-ccdc1f169aef",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We observe `üòê` with probability = 0.41792\n"
     ]
    }
   ],
   "source": [
    "test_value = `üòê`;\n",
    "N‚Çä = 0;\n",
    "for (key,value) ‚àà output_simulation_dict\n",
    "    if (value == test_value)\n",
    "        N‚Çä += 1\n",
    "    end\n",
    "end\n",
    "probability = N‚Çä/number_of_simulation_steps;\n",
    "println(\"We observe $(test_value) with probability = $(probability)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cb424c-917f-4573-9f8e-1df6139ef25a",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.1",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
